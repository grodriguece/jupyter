{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:02:03.641946Z",
     "start_time": "2021-01-02T17:02:03.638049Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T16:39:14.451198Z",
     "start_time": "2021-01-02T16:39:14.442703Z"
    }
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd \n",
    "import scattertext as st\n",
    "import swifter\n",
    "import spacy \n",
    "import pytextrank\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download from the cloud (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you didn't run preprocessing.ipynb, run this script to get the processed_train_data.csv from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T16:48:41.154290Z",
     "start_time": "2021-01-02T16:48:23.944522Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/uc?id=1jI1cmxqnwsmC-vbl8dNY6b4aNBtBbKy3'\n",
    "output = 'Twitter.zip'\n",
    "gdown.download(url, output, quiet=False) \n",
    "\n",
    "\n",
    "# Extract the zip file. The data is saved under Data directory\n",
    "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T16:48:52.750921Z",
     "start_time": "2021-01-02T16:48:52.534548Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('Data/processed_train_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T16:49:03.944738Z",
     "start_time": "2021-01-02T16:49:03.863925Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Pandas Apply: 100%|██████████| 3600/3600 [00:00<00:00, 102960.69it/s]\n"
     ]
    }
   ],
   "source": [
    "df.tweets = df.tweets.swifter.apply(lambda text: ' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T16:49:19.216735Z",
     "start_time": "2021-01-02T16:49:13.768853Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the parse feature to feed the class st.CorpusFromParsedDocuments later \n",
    "df['parse'] = df.tweets.swifter.apply(st.whitespace_nlp_with_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The step above can take a long time, if you prefer not to wait, interrupt the run and run the code below instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T16:52:07.631703Z",
     "start_time": "2021-01-02T16:52:03.955965Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('Data/processed_train_data_with_parse.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T16:52:08.304382Z",
     "start_time": "2021-01-02T16:52:08.274359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>gender</th>\n",
       "      <th>country</th>\n",
       "      <th>parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fucking terrify nemesis record bad enemy know ...</td>\n",
       "      <td>male</td>\n",
       "      <td>canada</td>\n",
       "      <td>(fucking, terrify, nemesis, record, bad, enemy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poetry shelf summer season poet pick poem pick...</td>\n",
       "      <td>female</td>\n",
       "      <td>new zealand</td>\n",
       "      <td>(poetry, shelf, summer, season, poet, pick, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say truth attest cloud sky joke how okay s coo...</td>\n",
       "      <td>female</td>\n",
       "      <td>canada</td>\n",
       "      <td>(say, truth, attest, cloud, sky, joke, how, ok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seem right pretty accurate new breakfast wrap ...</td>\n",
       "      <td>female</td>\n",
       "      <td>canada</td>\n",
       "      <td>(seem, right, pretty, accurate, new, breakfast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s word touch early leave night morning work ba...</td>\n",
       "      <td>male</td>\n",
       "      <td>ireland</td>\n",
       "      <td>(s, word, touch, early, leave, night, morning,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anticipation kill wait hope climb fall brillia...</td>\n",
       "      <td>female</td>\n",
       "      <td>great britain</td>\n",
       "      <td>(anticipation, kill, wait, hope, climb, fall, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>far sit greeting eye lilo stitch emosh day wee...</td>\n",
       "      <td>female</td>\n",
       "      <td>great britain</td>\n",
       "      <td>(far, sit, greeting, eye, lilo, stitch, emosh,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fantastic list resource beautiful social mediu...</td>\n",
       "      <td>female</td>\n",
       "      <td>great britain</td>\n",
       "      <td>(fantastic, list, resource, beautiful, social,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thank station gordon min record spin wait air ...</td>\n",
       "      <td>male</td>\n",
       "      <td>ireland</td>\n",
       "      <td>(thank, station, gordon, min, record, spin, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>work hope let film tomorrow biscuit home morni...</td>\n",
       "      <td>female</td>\n",
       "      <td>great britain</td>\n",
       "      <td>(work, hope, let, film, tomorrow, biscuit, hom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  gender        country  \\\n",
       "0  fucking terrify nemesis record bad enemy know ...    male         canada   \n",
       "1  poetry shelf summer season poet pick poem pick...  female    new zealand   \n",
       "2  say truth attest cloud sky joke how okay s coo...  female         canada   \n",
       "3  seem right pretty accurate new breakfast wrap ...  female         canada   \n",
       "4  s word touch early leave night morning work ba...    male        ireland   \n",
       "5  anticipation kill wait hope climb fall brillia...  female  great britain   \n",
       "6  far sit greeting eye lilo stitch emosh day wee...  female  great britain   \n",
       "7  fantastic list resource beautiful social mediu...  female  great britain   \n",
       "8  thank station gordon min record spin wait air ...    male        ireland   \n",
       "9  work hope let film tomorrow biscuit home morni...  female  great britain   \n",
       "\n",
       "                                               parse  \n",
       "0  (fucking, terrify, nemesis, record, bad, enemy...  \n",
       "1  (poetry, shelf, summer, season, poet, pick, po...  \n",
       "2  (say, truth, attest, cloud, sky, joke, how, ok...  \n",
       "3  (seem, right, pretty, accurate, new, breakfast...  \n",
       "4  (s, word, touch, early, leave, night, morning,...  \n",
       "5  (anticipation, kill, wait, hope, climb, fall, ...  \n",
       "6  (far, sit, greeting, eye, lilo, stitch, emosh,...  \n",
       "7  (fantastic, list, resource, beautiful, social,...  \n",
       "8  (thank, station, gordon, min, record, spin, wa...  \n",
       "9  (work, hope, let, film, tomorrow, biscuit, hom...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T16:52:17.704242Z",
     "start_time": "2021-01-02T16:52:11.064755Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(df, category_col='gender', parsed_col='parse'\n",
    "                                     ).build().get_unigram_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T16:52:21.520465Z",
     "start_time": "2021-01-02T16:52:19.576390Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reduce the number of phrases displayed in the chart to 2000 \n",
    "corpus = corpus.compact(st.AssociationCompactor(2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pmi_threshold_coefficient: Pointwise mutual information. 0 if two words are independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T16:52:24.882200Z",
     "start_time": "2021-01-02T16:52:23.282509Z"
    }
   },
   "outputs": [],
   "source": [
    "html = st.produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category='female', category_name='Female', not_category_name='Male',\n",
    "    minimum_term_frequency=0, pmi_threshold_coefficient=0,\n",
    "    width_in_pixels=1000, metadata=corpus.get_df()['country'],\n",
    "    transform=st.Scalers.dense_rank\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T16:52:26.447342Z",
     "start_time": "2021-01-02T16:52:26.401928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11870129"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('./tweets_gender.html', 'w').write(html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Phrase associations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [PyTextRank](https://github.com/DerwenAI/pytextrank) before running the code below.\n",
    "```bash\n",
    "pip install pytextrank\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T16:55:53.548006Z",
     "start_time": "2021-01-02T16:53:17.403287Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "df = df.assign(parse=lambda data: data.tweets.apply(nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T16:59:48.410122Z",
     "start_time": "2021-01-02T16:56:13.964407Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(\n",
    "    df,\n",
    "    category_col='gender',\n",
    "    parsed_col='parse',\n",
    "    feats_from_spacy_doc=st.PyTextRankPhrases()\n",
    ").build(\n",
    ").compact(\n",
    "    st.AssociationCompactor(2000, use_non_text_features=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:03:32.026018Z",
     "start_time": "2021-01-02T17:03:32.001933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <td>1.664847</td>\n",
       "      <td>1.617620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jewish</th>\n",
       "      <td>1.611201</td>\n",
       "      <td>0.893873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canadian</th>\n",
       "      <td>4.828005</td>\n",
       "      <td>5.083046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>democratic</th>\n",
       "      <td>1.200413</td>\n",
       "      <td>1.028026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>3.243414</td>\n",
       "      <td>2.122479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fact</th>\n",
       "      <td>3.845346</td>\n",
       "      <td>2.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoy</th>\n",
       "      <td>0.082487</td>\n",
       "      <td>0.234663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>2.676859</td>\n",
       "      <td>2.466787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summer day</th>\n",
       "      <td>0.336981</td>\n",
       "      <td>0.545745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly</th>\n",
       "      <td>1.087747</td>\n",
       "      <td>1.601123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                male    female\n",
       "term                          \n",
       "change      1.664847  1.617620\n",
       "jewish      1.611201  0.893873\n",
       "canadian    4.828005  5.083046\n",
       "democratic  1.200413  1.028026\n",
       "british     3.243414  2.122479\n",
       "fact        3.845346  2.889458\n",
       "annoy       0.082487  0.234663\n",
       "french      2.676859  2.466787\n",
       "summer day  0.336981  0.545745\n",
       "monthly     1.087747  1.601123"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_category_scores = corpus.get_metadata_freq_df('')\n",
    "term_category_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:05:23.480549Z",
     "start_time": "2021-01-02T17:05:23.415386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the rank of each term in each category\n",
    "term_ranks = np.argsort(np.argsort(-term_category_scores, axis=0), axis=0) + 1\n",
    "\n",
    "# Text displayed when a term is clicked\n",
    "metadata_descriptions = {\n",
    "    term: '<br/>' + '<br/>'.join(\n",
    "        '<b>%s</b> TextRank score rank: %s/%s' % (cat, term_ranks.loc[term, cat], corpus.get_num_metadata())\n",
    "        for cat in corpus.get_categories())\n",
    "    for term in corpus.get_metadata()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:25:37.997175Z",
     "start_time": "2021-01-02T17:25:37.920504Z"
    }
   },
   "outputs": [],
   "source": [
    "category_specific_prominence = term_category_scores.apply(\n",
    "    lambda r: r.female if r.female > r.male else -r.male,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:25:45.754294Z",
     "start_time": "2021-01-02T17:25:44.463519Z"
    }
   },
   "outputs": [],
   "source": [
    "html = st.produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category='female',\n",
    "    not_category_name='male',\n",
    "    minimum_term_frequency=0,\n",
    "    pmi_threshold_coefficient=0,\n",
    "    width_in_pixels=1000,\n",
    "    transform=st.dense_rank,\n",
    "    metadata=corpus.get_df()['country'],\n",
    "    scores=category_specific_prominence,\n",
    "    sort_by_dist=False,\n",
    "    use_non_text_features=True,\n",
    "    topic_model_term_lists={term: [term] for term in corpus.get_metadata()},\n",
    "    topic_model_preview_size=0,\n",
    "    metadata_descriptions=metadata_descriptions,\n",
    "    use_full_doc=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:25:46.520693Z",
     "start_time": "2021-01-02T17:25:46.415382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13521834"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('./tweets_gender_textrank.html', 'w').write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('scraping': conda)",
   "language": "python",
   "name": "python38364bitscrapingconda8891ca94cb9c435e8f8159bc20eab25f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
